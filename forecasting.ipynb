{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6df088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import unquote\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1488d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def historico(ticker, shifts):\n",
    "    # Obter os dados do ticker a partir do Yahoo Finance\n",
    "    df = yf.download(ticker, start=\"2013-01-01\")\n",
    "    # Renomear as colunas do DataFrame\n",
    "    df.rename(columns={'Volume': f'volume_{ticker}'}, inplace=True)\n",
    "    # Definir movimento do ticker\n",
    "    df[f'mov_{ticker}'] = df.apply(lambda row: 1 if row['Close'] > row['Open'] else 0, axis=1)\n",
    "    # Remover outliers usando o método do desvio padrão\n",
    "    std_dev = df[f'volume_{ticker}'].std()\n",
    "    df = df[df[f'volume_{ticker}'] < df[f'volume_{ticker}'].mean() + 3 * std_dev]\n",
    "\n",
    "    # Normalizar a coluna \"Volume\"\n",
    "    scaler = MinMaxScaler()\n",
    "    df_copy = df.copy()  # Criar uma cópia do DataFrame\n",
    "    df_copy[f'volume_{ticker}'] = scaler.fit_transform(df_copy[[f'volume_{ticker}']])\n",
    "    \n",
    "    # Deixando somente as colunas importantes\n",
    "    df_copy = df_copy[[(f'mov_{ticker}'),(f'volume_{ticker}')]]\n",
    "    \n",
    "    for coluna in df_copy.columns:\n",
    "        for shift in range(1, shifts):\n",
    "            df_copy[f'{coluna}_{shift}'] = df_copy[coluna].shift(shift)\n",
    "    \n",
    "    df_copy = df_copy.dropna()\n",
    "    df_copy = df_copy.drop(columns=(f'volume_{ticker}'))\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b476329",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = historico(\"ITUB4.SA\",1)\n",
    "resultado.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar ação do Bradesco\n",
    "df_bradesco = historico(\"BBDC4.SA\",6)\n",
    "df_bradesco.drop(columns={'mov_BBDC4.SA'}, inplace=True)\n",
    "\n",
    "# Adicionar ação do Santander\n",
    "df_santander = historico(\"SANB11.SA\",6)\n",
    "df_santander.drop(columns={'mov_SANB11.SA'}, inplace=True)\n",
    "\n",
    "# Adicionar ação do Santander\n",
    "df_b3 = historico(\"B3SA3.SA\",6)\n",
    "df_b3.drop(columns={'mov_B3SA3.SA'}, inplace=True)\n",
    "\n",
    "# Adicionar ação do Santander\n",
    "df_itau = historico(\"ITUB4.SA\",6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81589589",
   "metadata": {},
   "outputs": [],
   "source": [
    "bancos = df_itau.merge(df_bradesco, how = \"inner\",left_index = True, right_index = True)\n",
    "bancos = bancos.merge(df_santander, how = \"inner\",left_index = True, right_index = True)\n",
    "bancos = bancos.merge(df_b3, how = \"inner\",left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ddb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os parâmetros que serão testados no Decision Tree\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Criar o modelo Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Criar o objeto de busca em grade com cross-validation\n",
    "grid_search_dt = GridSearchCV(dt_model, param_grid=param_grid_dt, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Treinar o modelo usando o conjunto de treinamento\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Obter os melhores parâmetros encontrados\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "print(\"Melhores parâmetros para o Decision Tree:\", best_params_dt)\n",
    "\n",
    "# Fazer previsões no conjunto de teste usando o modelo com os melhores parâmetros\n",
    "y_pred_dt = grid_search_dt.predict(X_test)\n",
    "\n",
    "# Avaliar a precisão do modelo Decision Tree com os melhores parâmetros\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Precisão do Decision Tree com os melhores parâmetros:\", accuracy_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe192a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os parâmetros que serão testados no Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Criar o modelo Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Criar o objeto de busca em grade com cross-validation\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid=param_grid_rf, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Treinar o modelo usando o conjunto de treinamento\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Obter os melhores parâmetros encontrados\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Melhores parâmetros para o Random Forest:\", best_params_rf)\n",
    "\n",
    "# Fazer previsões no conjunto de teste usando o modelo com os melhores parâmetros\n",
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "\n",
    "# Avaliar a precisão do modelo Random Forest com os melhores parâmetros\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Precisão do Random Forest com os melhores parâmetros:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d555eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consequentes(df,col,pivot):\n",
    "    serie = df[col].values.tolist()\n",
    "    if pivot:\n",
    "        sobe_desce = [0,0,0]\n",
    "    if pivot == False:\n",
    "        sobe_desce = [0,0]\n",
    "    aux = 1\n",
    "    for item in range(len(serie)):\n",
    "        if serie[item] == 1 and aux > 0:\n",
    "            aux += 1\n",
    "            sobe_desce.append(aux)\n",
    "        elif serie[item] == 0 and aux < 0:\n",
    "            aux -= 1\n",
    "            sobe_desce.append(aux)\n",
    "        elif serie[item] == 1 and serie[item-1] == 0:\n",
    "            aux = 1\n",
    "            sobe_desce.append(aux)\n",
    "        elif serie[item] == 0 and serie[item-1] == 1:\n",
    "            aux = -1 \n",
    "            sobe_desce.append(aux)\n",
    "    df = df.dropna()    \n",
    "    df[f'{col}_consequente'] = sobe_desce\n",
    "    df[f'{col}_consequente'] = df[f'{col}_consequente'].shift(1)\n",
    "    df = df.dropna()\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8e4d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prever(df, coluna_a_prever,printar):\n",
    "    # Dividir os dados em recursos (X) e o valor alvo (y)\n",
    "    X = df.drop(columns=[coluna_a_prever])\n",
    "    y = df[coluna_a_prever]\n",
    "\n",
    "    # Dividir os dados em conjunto de treinamento e teste (80% treinamento, 20% teste)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Definir os parâmetros que serão testados no Decision Tree\n",
    "    param_grid_dt = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter': ['best', 'random'],\n",
    "        'max_depth': [None, 10, 20, 30, 40],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    print('iniciando DTC')\n",
    "    # Criar o modelo Decision Tree\n",
    "    dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    print('iniciando DTC - xval')\n",
    "    # Criar o objeto de busca em grade com cross-validation para o Decision Tree\n",
    "    grid_search_dt = GridSearchCV(dt_model, param_grid=param_grid_dt, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "    # Treinar o modelo usando o conjunto de treinamento\n",
    "    grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "    # Obter os melhores parâmetros encontrados para o Decision Tree\n",
    "    best_params_dt = grid_search_dt.best_params_\n",
    "\n",
    "    # Treinar o modelo Decision Tree com os melhores parâmetros encontrados\n",
    "    best_dt_model = DecisionTreeClassifier(random_state=42, **best_params_dt)\n",
    "    best_dt_model.fit(X_train, y_train)\n",
    "\n",
    "    # Fazer previsões no conjunto de teste usando o modelo Decision Tree\n",
    "    y_pred_decision_tree = best_dt_model.predict(X_test)\n",
    "\n",
    "    # Avaliar a precisão do modelo Decision Tree\n",
    "    accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "    print('done DTC')\n",
    "    # Definir os parâmetros que serão testados no Random Forest\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    print('iniciando RF')\n",
    "    # Criar o modelo Random Forest\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    print('iniciando RF - xval')\n",
    "    # Criar o objeto de busca em grade com cross-validation para o Random Forest\n",
    "    grid_search_rf = GridSearchCV(rf_model, param_grid=param_grid_rf, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "    # Treinar o modelo usando o conjunto de treinamento\n",
    "    grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Obter os melhores parâmetros encontrados para o Random Forest\n",
    "    best_params_rf = grid_search_rf.best_params_\n",
    "    print('Treinando RF')\n",
    "    # Treinar o modelo Random Forest com os melhores parâmetros encontrados\n",
    "    best_rf_model = RandomForestClassifier(random_state=42, **best_params_rf)\n",
    "    best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Fazer previsões no conjunto de teste usando o modelo Random Forest\n",
    "    y_pred_random_forest = best_rf_model.predict(X_test)\n",
    "\n",
    "    # Avaliar a precisão do modelo Random Forest\n",
    "    accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "    print('iniciando XGBOOST')\n",
    "    # Definir os parâmetros que serão testados no XGBoost\n",
    "    param_grid_xgb = {\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'n_estimators': [100, 200, 300]\n",
    "    }\n",
    "\n",
    "    # Criar o modelo XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "    # Criar o objeto de busca em grade com cross-validation para o XGBoost\n",
    "    grid_search_xgb = GridSearchCV(xgb_model, param_grid=param_grid_xgb, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "    # Treinar o modelo usando o conjunto de treinamento\n",
    "    grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Obter os melhores parâmetros encontrados para o XGBoost\n",
    "    best_params_xgb = grid_search_xgb.best_params_\n",
    "\n",
    "    # Treinar o modelo XGBoost com os melhores parâmetros encontrados\n",
    "    best_xgb_model = xgb.XGBClassifier(random_state=42, **best_params_xgb)\n",
    "    best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Fazer previsões no conjunto de teste usando o modelo XGBoost\n",
    "    y_pred_xgb = best_xgb_model.predict(X_test)\n",
    "    print('done XGboost')\n",
    "    # Avaliar a precisão do modelo XGBoost\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "    # Padronizar os dados de treinamento e teste para a rede neural\n",
    "    scaler = StandardScaler()\n",
    "    X_train_nn = scaler.fit_transform(X_train)\n",
    "    X_test_nn = scaler.transform(X_test)\n",
    "    print('iniciando RN')\n",
    "    # Construir a rede neural com camadas escondidas com o dobro de unidades\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_nn.shape[1],)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),  # Primeira camada escondida dobrada\n",
    "        tf.keras.layers.Dense(16, activation='relu'),  # Segunda camada escondida dobrada\n",
    "        tf.keras.layers.Dense(8, activation='relu'),   # Terceira camada escondida dobrada\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compilar o modelo\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Treinar a rede neural\n",
    "    model.fit(X_train_nn, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "    # Fazer previsões no conjunto de teste usando a rede neural\n",
    "    y_pred_prob = model.predict(X_test_nn)\n",
    "    y_pred_neural = (y_pred_prob > 0.5).astype(int)\n",
    "    print('Done RN')\n",
    "    # Avaliar a precisão da rede neural\n",
    "    accuracy_neural = accuracy_score(y_test, y_pred_neural)\n",
    "    if printar == True:\n",
    "        # Imprimir as precisões dos modelos\n",
    "        print(f'Precisão DTC: {grid_search_dt.best_score_:.4f}')\n",
    "        print(f'Precisão RF: {grid_search_rf.best_score_:.4f}')\n",
    "        print(f'Precisão XGBoost: {grid_search_xgb.best_score_:.4f}')\n",
    "        print(f'Precisão DTC com Melhores Parâmetros: {accuracy_decision_tree:.4f}')\n",
    "        print(f'Precisão RF com Melhores Parâmetros: {accuracy_random_forest:.4f}')\n",
    "        print(f'Precisão XGBoost com Melhores Parâmetros: {accuracy_xgb:.4f}')\n",
    "        print(f'Precisão RN: {accuracy_neural:.4f}')\n",
    "    return {\n",
    "        'DTC': accuracy_decision_tree,\n",
    "        'RF': accuracy_random_forest,\n",
    "        'XGBoost': accuracy_xgb,\n",
    "        'RN': accuracy_neural\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "baa67003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "iniciando DTC\n",
      "iniciando DTC - xval\n",
      "done DTC\n",
      "iniciando RF\n",
      "iniciando RF - xval\n",
      "Treinando RF\n",
      "iniciando XGBOOST\n",
      "done XGboost\n",
      "iniciando RN\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Done RN\n",
      "Precisão DTC: 0.5362\n",
      "Precisão RF: 0.5273\n",
      "Precisão XGBoost: 0.5437\n",
      "Precisão DTC com Melhores Parâmetros: 0.5050\n",
      "Precisão RF com Melhores Parâmetros: 0.4990\n",
      "Precisão XGBoost com Melhores Parâmetros: 0.5208\n",
      "Precisão RN: 0.5050\n",
      "Shift 3:\n",
      "Precisão DTC: 0.5050\n",
      "Precisão RF: 0.4990\n",
      "Precisão XGBoost: 0.5208\n",
      "Precisão RN: 0.5050\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "iniciando DTC\n",
      "iniciando DTC - xval\n",
      "done DTC\n",
      "iniciando RF\n",
      "iniciando RF - xval\n",
      "Treinando RF\n",
      "iniciando XGBOOST\n",
      "done XGboost\n",
      "iniciando RN\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Done RN\n",
      "Precisão DTC: 0.5318\n",
      "Precisão RF: 0.5298\n",
      "Precisão XGBoost: 0.5308\n",
      "Precisão DTC com Melhores Parâmetros: 0.5218\n",
      "Precisão RF com Melhores Parâmetros: 0.4841\n",
      "Precisão XGBoost com Melhores Parâmetros: 0.5437\n",
      "Precisão RN: 0.4881\n",
      "Shift 4:\n",
      "Precisão DTC: 0.5218\n",
      "Precisão RF: 0.4841\n",
      "Precisão XGBoost: 0.5437\n",
      "Precisão RN: 0.4881\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "iniciando DTC\n",
      "iniciando DTC - xval\n",
      "done DTC\n",
      "iniciando RF\n",
      "iniciando RF - xval\n",
      "Treinando RF\n",
      "iniciando XGBOOST\n",
      "done XGboost\n",
      "iniciando RN\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Done RN\n",
      "Precisão DTC: 0.5293\n",
      "Precisão RF: 0.5278\n",
      "Precisão XGBoost: 0.5213\n",
      "Precisão DTC com Melhores Parâmetros: 0.4524\n",
      "Precisão RF com Melhores Parâmetros: 0.5099\n",
      "Precisão XGBoost com Melhores Parâmetros: 0.5099\n",
      "Precisão RN: 0.4861\n",
      "Shift 5:\n",
      "Precisão DTC: 0.4524\n",
      "Precisão RF: 0.5099\n",
      "Precisão XGBoost: 0.5099\n",
      "Precisão RN: 0.4861\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "iniciando DTC\n",
      "iniciando DTC - xval\n",
      "done DTC\n",
      "iniciando RF\n",
      "iniciando RF - xval\n",
      "Treinando RF\n",
      "iniciando XGBOOST\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6624\\3833425733.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Chamar a função prever e obter as métricas de precisão\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mresultados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbancos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mov_ITUB4.SA\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprintar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# Atualizar os melhores resultados para cada modelo, se necessário\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6624\\59336118.py\u001b[0m in \u001b[0;36mprever\u001b[1;34m(df, coluna_a_prever, printar)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# Treinar o modelo usando o conjunto de treinamento\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[0mgrid_search_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;31m# Obter os melhores parâmetros encontrados para o XGBoost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Criar um dicionário para armazenar os melhores resultados de cada modelo\n",
    "melhores_resultados = {\n",
    "    'DTC': {'precisao': 0, 'shift': 0},\n",
    "    'RF': {'precisao': 0, 'shift': 0},\n",
    "    'XGBoost': {'precisao': 0, 'shift': 0},\n",
    "    'RN': {'precisao': 0, 'shift': 0}\n",
    "}\n",
    "\n",
    "for x in range(3, 10):\n",
    "    # Adicionar ação do Bradesco\n",
    "    df_bradesco = historico(\"BBDC4.SA\", x)\n",
    "    df_bradesco.drop(columns={'mov_BBDC4.SA'}, inplace=True)\n",
    "\n",
    "    # Adicionar ação do Santander\n",
    "    df_santander = historico(\"SANB11.SA\", x)\n",
    "    df_santander.drop(columns={'mov_SANB11.SA'}, inplace=True)\n",
    "\n",
    "    # Adicionar ação do B3\n",
    "    df_b3 = historico(\"B3SA3.SA\", x)\n",
    "    df_b3.drop(columns={'mov_B3SA3.SA'}, inplace=True)\n",
    "    \n",
    "    # Adicionar ação do BTG > Desempenho caiu\n",
    "    df_btg = historico(\"BPAC11.SA\", x)\n",
    "    df_btg.drop(columns={'mov_BPAC11.SA'}, inplace=True)\n",
    "\n",
    "    # Adicionar ação do Itaú\n",
    "    df_itau = historico(\"ITUB4.SA\", x)\n",
    "\n",
    "    # Montando dataframe\n",
    "    bancos = df_itau.merge(df_bradesco, how=\"inner\", left_index=True, right_index=True)\n",
    "    bancos = bancos.merge(df_santander, how=\"inner\", left_index=True, right_index=True)\n",
    "    #bancos = bancos.merge(df_btg, how=\"inner\", left_index=True, right_index=True)\n",
    "    bancos = bancos.merge(df_b3, how=\"inner\", left_index=True, right_index=True)\n",
    "    \n",
    "    if x == 3:\n",
    "        bancos = consequentes(bancos,\"mov_ITUB4.SA\",pivot = True)\n",
    "    if x == 4:\n",
    "        bancos = consequentes(bancos,\"mov_ITUB4.SA\",pivot = False)        \n",
    "    \n",
    "    # Chamar a função prever e obter as métricas de precisão\n",
    "    resultados = prever(bancos, \"mov_ITUB4.SA\", printar=True)\n",
    "\n",
    "    # Atualizar os melhores resultados para cada modelo, se necessário\n",
    "    if resultados['DTC'] > melhores_resultados['DTC']['precisao']:\n",
    "        melhores_resultados['DTC']['precisao'] = resultados['DTC']\n",
    "        melhores_resultados['DTC']['shift'] = x\n",
    "\n",
    "    if resultados['RF'] > melhores_resultados['RF']['precisao']:\n",
    "        melhores_resultados['RF']['precisao'] = resultados['RF']\n",
    "        melhores_resultados['RF']['shift'] = x\n",
    "\n",
    "    if resultados['XGBoost'] > melhores_resultados['XGBoost']['precisao']:\n",
    "        melhores_resultados['XGBoost']['precisao'] = resultados['XGBoost']\n",
    "        melhores_resultados['XGBoost']['shift'] = x\n",
    "\n",
    "    if resultados['RN'] > melhores_resultados['RN']['precisao']:\n",
    "        melhores_resultados['RN']['precisao'] = resultados['RN']\n",
    "        melhores_resultados['RN']['shift'] = x\n",
    "\n",
    "    print(f\"Shift {x}:\")\n",
    "    print(f\"Precisão DTC: {resultados['DTC']:.4f}\")\n",
    "    print(f\"Precisão RF: {resultados['RF']:.4f}\")\n",
    "    print(f\"Precisão XGBoost: {resultados['XGBoost']:.4f}\")\n",
    "    print(f\"Precisão RN: {resultados['RN']:.4f}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "\n",
    "# Imprimir os melhores resultados encontrados\n",
    "print(\"Melhores Resultados:\")\n",
    "print(f\"Melhor Precisão DTC: {melhores_resultados['DTC']['precisao']:.4f} - Shift {melhores_resultados['DTC']['shift']}\")\n",
    "print(f\"Melhor Precisão RF: {melhores_resultados['RF']['precisao']:.4f} - Shift {melhores_resultados['RF']['shift']}\")\n",
    "print(f\"Melhor Precisão XGBoost: {melhores_resultados['XGBoost']['precisao']:.4f} - Shift {melhores_resultados['XGBoost']['shift']}\")\n",
    "print(f\"Melhor Precisão RN: {melhores_resultados['RN']['precisao']:.4f} - Shift {melhores_resultados['RN']['shift']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
